{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BiznetGio Docs \uf0c1 BiznetGio Engineering Guide. BiznetGio Docs is built to serve as the developer guide to work with BiznetGio FOSS project or any other FOSS project that used by BiznetGio.","title":"Home"},{"location":"#biznetgio-docs","text":"BiznetGio Engineering Guide. BiznetGio Docs is built to serve as the developer guide to work with BiznetGio FOSS project or any other FOSS project that used by BiznetGio.","title":"BiznetGio Docs"},{"location":"about/contributing/","text":"Contributing to BiznetGio Docs \uf0c1 Quickstart \uf0c1 Install dependencies pip install - r requirements . txt Make your desired changes Review your changes with mkdocs serve Make pull request Project layout \uf0c1 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Deploy documentation \uf0c1 Info We use two branch. source to hold all the source contents, and master for compiled contents. mkdocs gh - deploy -- config - file ./ mkdocs . yml -- remote - branch master Or you can use CI automation: deploy : provider : pages skip_cleanup : true github_token : $github_token local_dir : site target_branch : master on : branch : source $github_token is the token than you generate from Github with the scope of public_repo and repo_deployment . Then put that token into your CI platform (such as Travis).","title":"Contributing"},{"location":"about/contributing/#contributing-to-biznetgio-docs","text":"","title":"Contributing to BiznetGio Docs"},{"location":"about/contributing/#quickstart","text":"Install dependencies pip install - r requirements . txt Make your desired changes Review your changes with mkdocs serve Make pull request","title":"Quickstart"},{"location":"about/contributing/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"about/contributing/#deploy-documentation","text":"Info We use two branch. source to hold all the source contents, and master for compiled contents. mkdocs gh - deploy -- config - file ./ mkdocs . yml -- remote - branch master Or you can use CI automation: deploy : provider : pages skip_cleanup : true github_token : $github_token local_dir : site target_branch : master on : branch : source $github_token is the token than you generate from Github with the scope of public_repo and repo_deployment . Then put that token into your CI platform (such as Travis).","title":"Deploy documentation"},{"location":"guide/boilerplates/","text":"Project Boilerplates \uf0c1 python-boilerplate \uf0c1 https://github.com/BiznetGIO/python-boilerplate Project Structure \uf0c1 This the the flask boilerplate that you can use to to kickstart your next REST API project. The app structure of this boilerplate is: . \u251c\u2500\u2500 app # application module \u2502 \u251c\u2500\u2500 configs \u2502 \u251c\u2500\u2500 controllers \u2502 \u2502 \u2514\u2500\u2500 api \u2502 \u251c\u2500\u2500 helpers \u2502 \u251c\u2500\u2500 libs \u2502 \u251c\u2500\u2500 middlewares \u2502 \u251c\u2500\u2500 models \u2502 \u2514\u2500\u2500 static \u251c\u2500\u2500 docker-compose.yml # docker compose config \u251c\u2500\u2500 Dockerfile # docker config \u251c\u2500\u2500 .dockerignore \u251c\u2500\u2500 .env.example # environment variable examples \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 README.md \u251c\u2500\u2500 requirements.txt # depedencies \u251c\u2500\u2500 run.sh \u2514\u2500\u2500 test configs : contains configuration variables. e.g API keys, database URIs, or variable of the application instance (things like DEBUG=True). You can ignore this if you are using docker environments. controllers/api : contains \"routes\" of the application. helpers : this directory act like \"helpers\" or \"utilitiles\" functions the applications libs : this directory act like \"vendor\", or any third-party module that you want to deliver within the application. middlewares : contains files that related to http request. e.g auth files. (you can ignore it at the beginning) models : contains models of the application. static : contains your static files .e.g images, javascript files. test : contains test suites against the application logic run.sh : contains files that will import the app and start the server. Quickstart \uf0c1 To start using this boilerplate: # install required dependencies $ pip install -r requirements.txt # run the app python manage.py server","title":"Project Boilerplates"},{"location":"guide/boilerplates/#project-boilerplates","text":"","title":"Project Boilerplates"},{"location":"guide/boilerplates/#python-boilerplate","text":"https://github.com/BiznetGIO/python-boilerplate","title":"python-boilerplate"},{"location":"guide/boilerplates/#project-structure","text":"This the the flask boilerplate that you can use to to kickstart your next REST API project. The app structure of this boilerplate is: . \u251c\u2500\u2500 app # application module \u2502 \u251c\u2500\u2500 configs \u2502 \u251c\u2500\u2500 controllers \u2502 \u2502 \u2514\u2500\u2500 api \u2502 \u251c\u2500\u2500 helpers \u2502 \u251c\u2500\u2500 libs \u2502 \u251c\u2500\u2500 middlewares \u2502 \u251c\u2500\u2500 models \u2502 \u2514\u2500\u2500 static \u251c\u2500\u2500 docker-compose.yml # docker compose config \u251c\u2500\u2500 Dockerfile # docker config \u251c\u2500\u2500 .dockerignore \u251c\u2500\u2500 .env.example # environment variable examples \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 README.md \u251c\u2500\u2500 requirements.txt # depedencies \u251c\u2500\u2500 run.sh \u2514\u2500\u2500 test configs : contains configuration variables. e.g API keys, database URIs, or variable of the application instance (things like DEBUG=True). You can ignore this if you are using docker environments. controllers/api : contains \"routes\" of the application. helpers : this directory act like \"helpers\" or \"utilitiles\" functions the applications libs : this directory act like \"vendor\", or any third-party module that you want to deliver within the application. middlewares : contains files that related to http request. e.g auth files. (you can ignore it at the beginning) models : contains models of the application. static : contains your static files .e.g images, javascript files. test : contains test suites against the application logic run.sh : contains files that will import the app and start the server.","title":"Project Structure"},{"location":"guide/boilerplates/#quickstart","text":"To start using this boilerplate: # install required dependencies $ pip install -r requirements.txt # run the app python manage.py server","title":"Quickstart"},{"location":"guide/common-errors/","text":"Common Errors \uf0c1 Docker \uf0c1 ERROR: Couldn't connect to Docker daemon at http+docker://localunixsocket - is it running? Add your current user to docker group then activates new permissions for docker group sudo usermod -a -G docker $USER newgrp docker Virtual machine \uf0c1 can't do ssh or scp to CentOS remote vm Change PasswordAuthentication in /etc/ssh/sshd_config 'PasswordAuthentication no' # to 'PasswordAuthentication yes' then restart the service sudo systemctl restart sshd","title":"Common Errors"},{"location":"guide/common-errors/#common-errors","text":"","title":"Common Errors"},{"location":"guide/common-errors/#docker","text":"ERROR: Couldn't connect to Docker daemon at http+docker://localunixsocket - is it running? Add your current user to docker group then activates new permissions for docker group sudo usermod -a -G docker $USER newgrp docker","title":"Docker"},{"location":"guide/common-errors/#virtual-machine","text":"can't do ssh or scp to CentOS remote vm Change PasswordAuthentication in /etc/ssh/sshd_config 'PasswordAuthentication no' # to 'PasswordAuthentication yes' then restart the service sudo systemctl restart sshd","title":"Virtual machine"},{"location":"guide/contrib-guide/","text":"Contributing to open source BiznetGio Project \uf0c1 We'd be happy for you to contribute! Support questions \uf0c1 Please, don't use the issue tracker for this. Use the preserved gitter channel in each project. Project organization \uf0c1 We only use one branch for the project: master branch. Tag will be created to mark stable release. Bug fix or Hot fix branches should be created for fixing bugs and merged into master when ready. Info we don't use master - development branch for monorepo. Instead we use <servicename>/<workitem> such as api/add-health-endpoint , and those branches will be merged into master eventually. Opening a new issue \uf0c1 Look through existing issues to see if your issue already exists. So we don't have duplicate issue . If your issue already exists, comment on its thread with any information you have. Even if this is simply to note that you are having the same problem, it is still helpful! Always be as descriptive as you can . What is the expected behavior? What is the actual behavior? What are the steps to reproduce? Attach screenshots, videos, GIFs if possible. Include <project> version or branch experiencing the issue. Include OS version experiencing the issue. Submitting a pull request \uf0c1 Find an issue to work on, or create a new one. Avoid duplicates, please check existing issues! Fork the repo, or make sure you are synced with the latest changes on master . Create a new branch with a sweet name: git checkout -b issue_<##>_<description> . Do code. Plese follow PEP8 Please watch your line length . It's advised to limit under 80 char. Write unit tests when applicable. Don't break unit tests or functionality. Update the documentation header comments if needed. Rebase on master branch and resolve any conflicts before submitting a pull request! Submit a pull request to the master branch. Make sure to add yourself to AUTHORS file. First time setup \uf0c1 Please refer to instalation guide and running test suitein each project.","title":"Contribution Guide"},{"location":"guide/contrib-guide/#contributing-to-open-source-biznetgio-project","text":"We'd be happy for you to contribute!","title":"Contributing to open source BiznetGio Project"},{"location":"guide/contrib-guide/#support-questions","text":"Please, don't use the issue tracker for this. Use the preserved gitter channel in each project.","title":"Support questions"},{"location":"guide/contrib-guide/#project-organization","text":"We only use one branch for the project: master branch. Tag will be created to mark stable release. Bug fix or Hot fix branches should be created for fixing bugs and merged into master when ready. Info we don't use master - development branch for monorepo. Instead we use <servicename>/<workitem> such as api/add-health-endpoint , and those branches will be merged into master eventually.","title":"Project organization"},{"location":"guide/contrib-guide/#opening-a-new-issue","text":"Look through existing issues to see if your issue already exists. So we don't have duplicate issue . If your issue already exists, comment on its thread with any information you have. Even if this is simply to note that you are having the same problem, it is still helpful! Always be as descriptive as you can . What is the expected behavior? What is the actual behavior? What are the steps to reproduce? Attach screenshots, videos, GIFs if possible. Include <project> version or branch experiencing the issue. Include OS version experiencing the issue.","title":"Opening a new issue"},{"location":"guide/contrib-guide/#submitting-a-pull-request","text":"Find an issue to work on, or create a new one. Avoid duplicates, please check existing issues! Fork the repo, or make sure you are synced with the latest changes on master . Create a new branch with a sweet name: git checkout -b issue_<##>_<description> . Do code. Plese follow PEP8 Please watch your line length . It's advised to limit under 80 char. Write unit tests when applicable. Don't break unit tests or functionality. Update the documentation header comments if needed. Rebase on master branch and resolve any conflicts before submitting a pull request! Submit a pull request to the master branch. Make sure to add yourself to AUTHORS file.","title":"Submitting a pull request"},{"location":"guide/contrib-guide/#first-time-setup","text":"Please refer to instalation guide and running test suitein each project.","title":"First time setup"},{"location":"guide/deploy-app/","text":"Deploying Application \uf0c1 Create your Virtual Machine \uf0c1 login into https://horizon.neo.id/ . Ask the credential to your team. create new vm: go to \"compute \u2192 instances\", select \"launch instance\" fill appropriate \"instance name\" and other fields. choose CentOS in \"source\" for the sake of similarity. choose your flavour size ask your team what \"network\" to use. ask your team what \"security group\" to use. ask your team what \"keypair\" to use. Ignore \"network prort\", \"configuration\", \"server group\", \"scheduler\", and \"metadata\" for now. select \"launch instance\" Get your private key \uf0c1 get the \"private-key\" by visiting \"orchestration \u2192 stack \u2192 your-vm-key \u2192 overview\" copy that \"private-key\" to write that to a file with appropriate name in your local machine. e.g key.pem run chmod 600 key.pem Accessing your VM \uf0c1 Do it with ssh: ssh -i /path/to/your/vm-key.pem <your-vm-username>@<public-ip> then do your business there. Commonly installing docker and docker-compose sudo yum install docker # installing docker # installing docker-compose (yes, it's not in centos repo) sudo yum install epel-release sudo yum install -y python-pip sudo pip install docker-compose Taking your image to your vm \uf0c1 Note It's advicable to avoid using Docker Hub for our development image. It's also not suitable way of doing managing internal projects. Use scp for the win! Sadly, scp will not work seamlessly in centos . You need to change: 'PasswordAuthentication no' # to 'PasswordAuthentication yes' in \"/etc/ssh/sshd_config\", then re-started the service sudo systemctl restart sshd Prepare your image to be transferred using SCP \uf0c1 save docker as tar docker save -o <path for generated tar file> <image name> move from your local machine to remote vm scp -i /path/to/key.pem whois-api.tar <username>@<public-ip>:~/your/destination/dir/ cd to your \"destionation/dir\" then load the image docker load -i <path to image tar file> Run the app \uf0c1 Run the app as you did in local machine $ docker-compose up","title":"Deploying App"},{"location":"guide/deploy-app/#deploying-application","text":"","title":"Deploying Application"},{"location":"guide/deploy-app/#create-your-virtual-machine","text":"login into https://horizon.neo.id/ . Ask the credential to your team. create new vm: go to \"compute \u2192 instances\", select \"launch instance\" fill appropriate \"instance name\" and other fields. choose CentOS in \"source\" for the sake of similarity. choose your flavour size ask your team what \"network\" to use. ask your team what \"security group\" to use. ask your team what \"keypair\" to use. Ignore \"network prort\", \"configuration\", \"server group\", \"scheduler\", and \"metadata\" for now. select \"launch instance\"","title":"Create your Virtual Machine"},{"location":"guide/deploy-app/#get-your-private-key","text":"get the \"private-key\" by visiting \"orchestration \u2192 stack \u2192 your-vm-key \u2192 overview\" copy that \"private-key\" to write that to a file with appropriate name in your local machine. e.g key.pem run chmod 600 key.pem","title":"Get your private key"},{"location":"guide/deploy-app/#accessing-your-vm","text":"Do it with ssh: ssh -i /path/to/your/vm-key.pem <your-vm-username>@<public-ip> then do your business there. Commonly installing docker and docker-compose sudo yum install docker # installing docker # installing docker-compose (yes, it's not in centos repo) sudo yum install epel-release sudo yum install -y python-pip sudo pip install docker-compose","title":"Accessing your VM"},{"location":"guide/deploy-app/#taking-your-image-to-your-vm","text":"Note It's advicable to avoid using Docker Hub for our development image. It's also not suitable way of doing managing internal projects. Use scp for the win! Sadly, scp will not work seamlessly in centos . You need to change: 'PasswordAuthentication no' # to 'PasswordAuthentication yes' in \"/etc/ssh/sshd_config\", then re-started the service sudo systemctl restart sshd","title":"Taking your image to your vm"},{"location":"guide/deploy-app/#prepare-your-image-to-be-transferred-using-scp","text":"save docker as tar docker save -o <path for generated tar file> <image name> move from your local machine to remote vm scp -i /path/to/key.pem whois-api.tar <username>@<public-ip>:~/your/destination/dir/ cd to your \"destionation/dir\" then load the image docker load -i <path to image tar file>","title":"Prepare your image to be transferred using SCP"},{"location":"guide/deploy-app/#run-the-app","text":"Run the app as you did in local machine $ docker-compose up","title":"Run the app"},{"location":"guide/dockerize-flask/","text":"Dockerzie Flask Application \uf0c1 Docker Clash Course \uf0c1 [ start ] sudo systemctl start docker ( debian based ) sudo service docker { stop | start | restart } ( centos ) [ build ] docker build -t whois-api:latest . [ List container ] docker ps -a ## list all docker ps -l ## list latest image [ List image ] docker image ls [ remove ] docker rmi -f $( docker images -f \"dangling=true\" -q ) ## daggling images Docker Intro \uf0c1 Make sure you have installed docker and docker-compose. Verify your installation by checking their version Add the Dockerfile ## we choose alpine for the sake of tiny size FROM python:3.7-alpine RUN pip3 install gunicorn ## wsgi server in your container ## choose 'app' as workdir. Docker will create if it doesn't exists WORKDIR /app # copy just the requirements.txt first to leverage Docker cache COPY ./requirements.txt /app/requirements.txt RUN pip3 install -r /app/requirements.txt COPY . /app ## define the port you will be using EXPOSE 5000 Read Dockerfilereference documentation to learn more about these keywords. To learn more about Alpine OS apk command read Alpine Linux package management wiki . Leveraging Docker build cache documented in Dockerfile Bestpractice Build the image \uf0c1 docker build -t flask-tutorial:0.0.1 . - -t : to tag your image name - . : current dir (bash syntax) Running the container \uf0c1 For the sake of ease, we will use docker-compose to run the container. Note Please discuss with your team, what port you will be using and what OS variable that you need (if you use environment keyword) Then, add the appropriate docker-compose.yml file: ## remove anyline like this, I am just a description version : '3' services : whois : ## your container name image : flask-tutorial:0.0.1 ## your image name (that you built earlier) with the tag ports : ## the port on your `HOST:CONTAINER` - \"5000:5000\" environment : ## discuss with your team what to put here - APP_HOST=0.0.0.0 - APP_PORT=5000 - WHOIS_KEY=fakekey123 command : sh run.sh server production Read Docker Compose documentation to learn more about these keyword. Run the app when everything ok $ docker-compose up","title":"Dockerize Flask App"},{"location":"guide/dockerize-flask/#dockerzie-flask-application","text":"","title":"Dockerzie Flask Application"},{"location":"guide/dockerize-flask/#docker-clash-course","text":"[ start ] sudo systemctl start docker ( debian based ) sudo service docker { stop | start | restart } ( centos ) [ build ] docker build -t whois-api:latest . [ List container ] docker ps -a ## list all docker ps -l ## list latest image [ List image ] docker image ls [ remove ] docker rmi -f $( docker images -f \"dangling=true\" -q ) ## daggling images","title":"Docker Clash Course"},{"location":"guide/dockerize-flask/#docker-intro","text":"Make sure you have installed docker and docker-compose. Verify your installation by checking their version Add the Dockerfile ## we choose alpine for the sake of tiny size FROM python:3.7-alpine RUN pip3 install gunicorn ## wsgi server in your container ## choose 'app' as workdir. Docker will create if it doesn't exists WORKDIR /app # copy just the requirements.txt first to leverage Docker cache COPY ./requirements.txt /app/requirements.txt RUN pip3 install -r /app/requirements.txt COPY . /app ## define the port you will be using EXPOSE 5000 Read Dockerfilereference documentation to learn more about these keywords. To learn more about Alpine OS apk command read Alpine Linux package management wiki . Leveraging Docker build cache documented in Dockerfile Bestpractice","title":"Docker Intro"},{"location":"guide/dockerize-flask/#build-the-image","text":"docker build -t flask-tutorial:0.0.1 . - -t : to tag your image name - . : current dir (bash syntax)","title":"Build the image"},{"location":"guide/dockerize-flask/#running-the-container","text":"For the sake of ease, we will use docker-compose to run the container. Note Please discuss with your team, what port you will be using and what OS variable that you need (if you use environment keyword) Then, add the appropriate docker-compose.yml file: ## remove anyline like this, I am just a description version : '3' services : whois : ## your container name image : flask-tutorial:0.0.1 ## your image name (that you built earlier) with the tag ports : ## the port on your `HOST:CONTAINER` - \"5000:5000\" environment : ## discuss with your team what to put here - APP_HOST=0.0.0.0 - APP_PORT=5000 - WHOIS_KEY=fakekey123 command : sh run.sh server production Read Docker Compose documentation to learn more about these keyword. Run the app when everything ok $ docker-compose up","title":"Running the container"},{"location":"guide/knot-clash-course/","text":"Knot Clash Course \uf0c1 Quickstart \uf0c1 installation: $ sudo apt-get install knot run knot: $ sudo systemctl start knot # to check if it's running $ sudo systemctl status knot Server login \uf0c1 copy the key and put it into a key.pem file change it's mode: chmod 600 key.pem get your server ip (.e.g from your horizon portal) log to your machine using ssh $ ssh -i key.pem centos@<your ip master> Accessible machine (the one that had the public Ips) are only the slaves. To access the servers that had private IPs (including master). Use the key file inside the slave servers. to log to server that didn't have public IPs. [ centos@cmg01z00knsl001 ~ ] $ ls # this in in master server STAGING STAGING.tar.gz vm-key.pem [ centos@cmg01z00knsl001 ~ ] $ ssh -i vm-key.pem centos@<slave ip> [ centos@vultr-test-1 ~ ] $ # logged into slave server We use the following format, to name our servers: <serverlocation | servernumber | purpose | rule | number> e.g: cmg01z00knms001: for master cmg01z00knsl001: for slave Knot setups \uf0c1 Ensure all old files removed Warning Do this only if you knot what you are doing, otherwise jump directly to \"start adding zone\" at the next step\" rm -rf * /var/lib/knot # knot database rm -rf * /etc/knot # knot config rm -rf * /run/knot # knot socket start the knot # systemctl start knot The initial file of knot (after removing all contents in /var/lib/knot/ and /etc/knot/ ) are only the timers directory in /var/lib/knot/ start adding zone (or other things) sudo knotc conf-init Start knotc conf-init . This step only requered if you have fresh knot installation. This will add confdb directory in /var/lib/knot/ . To check the content of knot database, you can do export it to the file: # knotc conf-export /etc/knot/knot.conf # to check it's content # cat /etc/knot/knot.conf Adding config (simple example) \uf0c1 # knotc conf-begin ## start every command with `*-begin` OK # knotc conf-set server.version \"None of your bussiness\" OK # knotc conf-set server.listen \"0.0.0.0@53\" OK # knotc conf-commit ## end every command with `*-commit` OK # knotc conf-read # to see knot db content server.version = None of your bussiness server.listen = 0 .0.0.0@53 This will put the value to knot database. To export it to file (e.g knot.conf) you can do knotc conf-export /etc/knot/knot.conf . But entering value one by one using knotc is tedious. You can add them to a file in: /etc/knot.conf then import to the knot db: knotc conf-import knot.conf Adding zone (SOA example) \uf0c1 # knotc zone-begin lapar.io # knotc zone-set lapar.io. @ 86400 SOA ns1.biz.net.id. hostmaster.biz.net.id. 2018070410 10800 3600 604800 38400 # knotc zone-commit lapar.io OK # check if it's okay # knotc zone-read lapar.io [ lapar.io. ] lapar.io. 86400 SOA ns1.biz.net.id. hostmaster.biz.net.id. 2018070410 10800 3600 604800 38400 Adding zone (NS example) \uf0c1 # knotc zone-begin lapar.io OK # knotc zone-set lapar.io. @ 14000 NS ns1.biznet.id. OK # knotc zone-commit lapar.io # knotc zone-read lapar.io [ lapar.io. ] lapar.io. 14000 NS ns1.biznet.id. [ lapar.io. ] lapar.io. 86400 SOA ns1.biz.net.id. hostmaster.biz.net.id. 2018070411 10800 3600 604800 38400 Adding zone (A example) \uf0c1 # knotc zone-begin lapar.io OK # knotc zone-set lapar.io. @ 3600 A 127.0.0.1 # knotc zone-commit lapar.io Testing the result \uf0c1 kdig @localhost lapar.io SOA +tcp kdig @localhost lapar.io A +tcp Additional information \uf0c1 To learn more consult knot documentation","title":"Knot Clash Course"},{"location":"guide/knot-clash-course/#knot-clash-course","text":"","title":"Knot Clash Course"},{"location":"guide/knot-clash-course/#quickstart","text":"installation: $ sudo apt-get install knot run knot: $ sudo systemctl start knot # to check if it's running $ sudo systemctl status knot","title":"Quickstart"},{"location":"guide/knot-clash-course/#server-login","text":"copy the key and put it into a key.pem file change it's mode: chmod 600 key.pem get your server ip (.e.g from your horizon portal) log to your machine using ssh $ ssh -i key.pem centos@<your ip master> Accessible machine (the one that had the public Ips) are only the slaves. To access the servers that had private IPs (including master). Use the key file inside the slave servers. to log to server that didn't have public IPs. [ centos@cmg01z00knsl001 ~ ] $ ls # this in in master server STAGING STAGING.tar.gz vm-key.pem [ centos@cmg01z00knsl001 ~ ] $ ssh -i vm-key.pem centos@<slave ip> [ centos@vultr-test-1 ~ ] $ # logged into slave server We use the following format, to name our servers: <serverlocation | servernumber | purpose | rule | number> e.g: cmg01z00knms001: for master cmg01z00knsl001: for slave","title":"Server login"},{"location":"guide/knot-clash-course/#knot-setups","text":"Ensure all old files removed Warning Do this only if you knot what you are doing, otherwise jump directly to \"start adding zone\" at the next step\" rm -rf * /var/lib/knot # knot database rm -rf * /etc/knot # knot config rm -rf * /run/knot # knot socket start the knot # systemctl start knot The initial file of knot (after removing all contents in /var/lib/knot/ and /etc/knot/ ) are only the timers directory in /var/lib/knot/ start adding zone (or other things) sudo knotc conf-init Start knotc conf-init . This step only requered if you have fresh knot installation. This will add confdb directory in /var/lib/knot/ . To check the content of knot database, you can do export it to the file: # knotc conf-export /etc/knot/knot.conf # to check it's content # cat /etc/knot/knot.conf","title":"Knot setups"},{"location":"guide/knot-clash-course/#adding-config-simple-example","text":"# knotc conf-begin ## start every command with `*-begin` OK # knotc conf-set server.version \"None of your bussiness\" OK # knotc conf-set server.listen \"0.0.0.0@53\" OK # knotc conf-commit ## end every command with `*-commit` OK # knotc conf-read # to see knot db content server.version = None of your bussiness server.listen = 0 .0.0.0@53 This will put the value to knot database. To export it to file (e.g knot.conf) you can do knotc conf-export /etc/knot/knot.conf . But entering value one by one using knotc is tedious. You can add them to a file in: /etc/knot.conf then import to the knot db: knotc conf-import knot.conf","title":"Adding config (simple example)"},{"location":"guide/knot-clash-course/#adding-zone-soa-example","text":"# knotc zone-begin lapar.io # knotc zone-set lapar.io. @ 86400 SOA ns1.biz.net.id. hostmaster.biz.net.id. 2018070410 10800 3600 604800 38400 # knotc zone-commit lapar.io OK # check if it's okay # knotc zone-read lapar.io [ lapar.io. ] lapar.io. 86400 SOA ns1.biz.net.id. hostmaster.biz.net.id. 2018070410 10800 3600 604800 38400","title":"Adding zone (SOA example)"},{"location":"guide/knot-clash-course/#adding-zone-ns-example","text":"# knotc zone-begin lapar.io OK # knotc zone-set lapar.io. @ 14000 NS ns1.biznet.id. OK # knotc zone-commit lapar.io # knotc zone-read lapar.io [ lapar.io. ] lapar.io. 14000 NS ns1.biznet.id. [ lapar.io. ] lapar.io. 86400 SOA ns1.biz.net.id. hostmaster.biz.net.id. 2018070411 10800 3600 604800 38400","title":"Adding zone (NS example)"},{"location":"guide/knot-clash-course/#adding-zone-a-example","text":"# knotc zone-begin lapar.io OK # knotc zone-set lapar.io. @ 3600 A 127.0.0.1 # knotc zone-commit lapar.io","title":"Adding zone (A example)"},{"location":"guide/knot-clash-course/#testing-the-result","text":"kdig @localhost lapar.io SOA +tcp kdig @localhost lapar.io A +tcp","title":"Testing the result"},{"location":"guide/knot-clash-course/#additional-information","text":"To learn more consult knot documentation","title":"Additional information"},{"location":"guide/knot-setups/","text":"RESTKnot Setup \uf0c1 Installations \uf0c1 Install etcd & knot apt install knot libknot8 etcd Start knot & etcd sudo systemctl start etcd sudo systemctl start knot # check if they are running sudo systemctl status etcd sudo systemctl status knot Run kafka & zookeeper (using docker container) create file docker-compose.yml which contains: version: '3' services: zookeeper: image: wurstmeister/zookeeper kafka: image: wurstmeister/kafka ports: - \"9092:9092\" environment: KAFKA_ADVERTISED_HOST_NAME: localhost KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 Then run it with: docker-compose up Setups \uf0c1 Setup knot \uf0c1 sudo knotc conf-init # trigger knot db to save configs Setup the RESTKnot agent \uf0c1 # create venv mkvirtualenv rest-knot --python = /usr/bin/python3.7 # install agent dependencies cd RESTKnot/agent/ pip install -r requirements.txt pip install -e . Set broker and knot value sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent envi broker sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent envi knot Value example: Info Each operating system has different location of libknot.so and it's socket, so check it carefully. # knot env value example OS_KNOT_LIB = libknot.so OS_KNOT_SOCKS = /var/run/knot/knot.sock # broker env value example OS_BROKER = localhost OS_PORTS = 9092 OS_TOPIC = domaindata OS_FLAGS = master OS_GROUP = cmgz_master Check value sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent envi show -e broker Start the agent sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent start master Setup the RESTKnot API \uf0c1 Install API dependencies cd RESTKnot/api/ pip install -r requirements.txt pip install -e . Populate data to etcd cd RESTKnot/api/ python migrate_db.py Run RESTKnot API # for development sh run.sh server development # for production sh run.sh server production Test the result \uf0c1 $ curl 127 .0.0.1:5000/api/zone/list { \"code\" :200, \"count\" :1, \"data\" : [ { \"key\" : \"1\" , \"value\" : \"example1.com\" , \"created_at\" : \"2019-09-30 20:05:13.486640\" , \"user\" : { \"key\" : \"1\" , \"email\" : \"admin@foo.com\" , \"project_id\" : \"001\" , \"state\" : \"inserted\" , \"created_at\" : \"2019-07-20 23:04:22.420505\" } } ] , \"Status\" : \"success\" , \"message\" : \"Operation succeeded\" }","title":"RESTKnot Setup"},{"location":"guide/knot-setups/#restknot-setup","text":"","title":"RESTKnot Setup"},{"location":"guide/knot-setups/#installations","text":"Install etcd & knot apt install knot libknot8 etcd Start knot & etcd sudo systemctl start etcd sudo systemctl start knot # check if they are running sudo systemctl status etcd sudo systemctl status knot Run kafka & zookeeper (using docker container) create file docker-compose.yml which contains: version: '3' services: zookeeper: image: wurstmeister/zookeeper kafka: image: wurstmeister/kafka ports: - \"9092:9092\" environment: KAFKA_ADVERTISED_HOST_NAME: localhost KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 Then run it with: docker-compose up","title":"Installations"},{"location":"guide/knot-setups/#setups","text":"","title":"Setups"},{"location":"guide/knot-setups/#setup-knot","text":"sudo knotc conf-init # trigger knot db to save configs","title":"Setup knot"},{"location":"guide/knot-setups/#setup-the-restknot-agent","text":"# create venv mkvirtualenv rest-knot --python = /usr/bin/python3.7 # install agent dependencies cd RESTKnot/agent/ pip install -r requirements.txt pip install -e . Set broker and knot value sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent envi broker sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent envi knot Value example: Info Each operating system has different location of libknot.so and it's socket, so check it carefully. # knot env value example OS_KNOT_LIB = libknot.so OS_KNOT_SOCKS = /var/run/knot/knot.sock # broker env value example OS_BROKER = localhost OS_PORTS = 9092 OS_TOPIC = domaindata OS_FLAGS = master OS_GROUP = cmgz_master Check value sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent envi show -e broker Start the agent sudo /home/azzamsya/.virtualenvs/rest-knot/bin/dnsagent start master","title":"Setup the RESTKnot agent"},{"location":"guide/knot-setups/#setup-the-restknot-api","text":"Install API dependencies cd RESTKnot/api/ pip install -r requirements.txt pip install -e . Populate data to etcd cd RESTKnot/api/ python migrate_db.py Run RESTKnot API # for development sh run.sh server development # for production sh run.sh server production","title":"Setup the RESTKnot API"},{"location":"guide/knot-setups/#test-the-result","text":"$ curl 127 .0.0.1:5000/api/zone/list { \"code\" :200, \"count\" :1, \"data\" : [ { \"key\" : \"1\" , \"value\" : \"example1.com\" , \"created_at\" : \"2019-09-30 20:05:13.486640\" , \"user\" : { \"key\" : \"1\" , \"email\" : \"admin@foo.com\" , \"project_id\" : \"001\" , \"state\" : \"inserted\" , \"created_at\" : \"2019-07-20 23:04:22.420505\" } } ] , \"Status\" : \"success\" , \"message\" : \"Operation succeeded\" }","title":"Test the result"},{"location":"guide/standards/","text":"Developer Standadrd \uf0c1 Style Guide \uf0c1 Python \uf0c1 We use black for code formatter, and pre-commit for it's automation . Read Black editor integration for more information. To enforce PEP-08 standard we use flake8 , and integrate it's plugin to our code editor. Commit Message Guide \uf0c1 We use the pattern bellow for commit message: Add: <your commit message> Update: <your commit message> Remove: <your commit message> Fix: <your commit message> - Add : for feature additions. - Update : for feature update. - Remove : for feature dropping, etc. - Fix : for bug fixing, style, etc. Code standard \uf0c1 We adhere to clean code ideology. Most common things such as: meaningless / ambigous variable name: x , y , ymdstr .","title":"Standards"},{"location":"guide/standards/#developer-standadrd","text":"","title":"Developer Standadrd"},{"location":"guide/standards/#style-guide","text":"","title":"Style Guide"},{"location":"guide/standards/#python","text":"We use black for code formatter, and pre-commit for it's automation . Read Black editor integration for more information. To enforce PEP-08 standard we use flake8 , and integrate it's plugin to our code editor.","title":"Python"},{"location":"guide/standards/#commit-message-guide","text":"We use the pattern bellow for commit message: Add: <your commit message> Update: <your commit message> Remove: <your commit message> Fix: <your commit message> - Add : for feature additions. - Update : for feature update. - Remove : for feature dropping, etc. - Fix : for bug fixing, style, etc.","title":"Commit Message Guide"},{"location":"guide/standards/#code-standard","text":"We adhere to clean code ideology. Most common things such as: meaningless / ambigous variable name: x , y , ymdstr .","title":"Code standard"},{"location":"guide/test-minimalist/","text":"Magic Tricks of Testing (summary) Sandy Metz \uf0c1 Incoming \uf0c1 Incoming Query (Assert Result) \uf0c1 class Whell : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class TestWheel : def test_calculates_diameter ( self ): wheel = Whell ( 26 , 1.5 ) assert wheel . diameter () == 29 ## \u2b06 Test the return value (result) Incoming (private) Query \uf0c1 class Wheel : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class Gear : def __init__ ( self , chainring , cog , wheel ): self . chainring = chainring self . cog = cog self . wheel = wheel def _ratio ( self ): return self . chainring / self . cog def gear_inches ( self ): return self . _ratio () * self . wheel . diameter () # call private method class TestGear : def test_calculates_gear_inches ( self ): wheel = Wheel ( 26 , 1.5 ) gear = Gear ( 52 , 11 , wheel ) assert gear . gear_inches () == pytest . approx ( 137 , 0.01 ) ## \u2b06 test the interface, not the implementation ## (without private function) Incoming Command (Assert public side effect) \uf0c1 class Gear : def __init__ ( self ): self . cog = 0 def get_cog ( self ): return self . cog def set_cog ( self , cog ): self . cog = cog class TestGear : def test_set_cog ( self ): gear = Gear () gear . set_cog ( 27 ) assert gear . cog == 27 ## \u2b06 assert public side effect To Self \uf0c1 Sent to self (Ignore) \uf0c1 class Wheel : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class Gear : def __init__ ( self , chainring , cog , wheel ): self . chainring = chainring self . cog = cog self . wheel = wheel def _ratio ( self ): return self . chainring / self . cog def gear_inches ( self ): return self . _ratio () * self . wheel . diameter () # call private method class TestGear : def test_calculates_ratio ( self ): ## \u2b05 test private method wheel = Wheel ( 26 , 1.5 ) gear = Gear ( 52 , 11 , wheel ) assert gear . _ratio == pytest . approx ( 4.7 , 0.01 ) ## call to self ## \u2b06 this is redundant test. `gear_inches` return value is proof enough ## don\u2019t test private method (assert / expectation). Don\u2019t! Outgoing \uf0c1 Outgoing Query (Ignore) \uf0c1 class Wheel : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class Gear : def __init__ ( self , chainring , cog , wheel ): self . chainring = chainring self . cog = cog self . wheel = wheel def _ratio ( self ): return self . chainring / self . cog def gear_inches ( self ): return self . _ratio () * self . wheel . diameter () # call other class (outgoing) class TestGear : def test_calculates_gear_inches ( self ): wheel = Wheel ( 26 , 1.5 ) gear = Gear ( 52 , 11 , wheel ) # test outgoing command `wheel.diameter()` assert gear . wheel . diameter () == 29 ## \u2b06 this is already done in `Wheel` test (redundant) Outgoing Command (Expect to send) \uf0c1 # assert someting (side effect) in far away. # This is not `Gear` responsibility. # This is an integration test, not unit test. Credits \uf0c1 https://www.youtube.com/watch?v=URSWYvyc42M https://speakerdeck.com/skmetz/magic-tricks-of-testing-railsconf","title":"Testing Minimalist"},{"location":"guide/test-minimalist/#magic-tricks-of-testing-summary-sandy-metz","text":"","title":"Magic Tricks of Testing (summary) Sandy Metz"},{"location":"guide/test-minimalist/#incoming","text":"","title":"Incoming"},{"location":"guide/test-minimalist/#incoming-query-assert-result","text":"class Whell : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class TestWheel : def test_calculates_diameter ( self ): wheel = Whell ( 26 , 1.5 ) assert wheel . diameter () == 29 ## \u2b06 Test the return value (result)","title":"Incoming Query  (Assert Result)"},{"location":"guide/test-minimalist/#incoming-private-query","text":"class Wheel : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class Gear : def __init__ ( self , chainring , cog , wheel ): self . chainring = chainring self . cog = cog self . wheel = wheel def _ratio ( self ): return self . chainring / self . cog def gear_inches ( self ): return self . _ratio () * self . wheel . diameter () # call private method class TestGear : def test_calculates_gear_inches ( self ): wheel = Wheel ( 26 , 1.5 ) gear = Gear ( 52 , 11 , wheel ) assert gear . gear_inches () == pytest . approx ( 137 , 0.01 ) ## \u2b06 test the interface, not the implementation ## (without private function)","title":"Incoming (private) Query"},{"location":"guide/test-minimalist/#incoming-command-assert-public-side-effect","text":"class Gear : def __init__ ( self ): self . cog = 0 def get_cog ( self ): return self . cog def set_cog ( self , cog ): self . cog = cog class TestGear : def test_set_cog ( self ): gear = Gear () gear . set_cog ( 27 ) assert gear . cog == 27 ## \u2b06 assert public side effect","title":"Incoming Command (Assert public side effect)"},{"location":"guide/test-minimalist/#to-self","text":"","title":"To Self"},{"location":"guide/test-minimalist/#sent-to-self-ignore","text":"class Wheel : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class Gear : def __init__ ( self , chainring , cog , wheel ): self . chainring = chainring self . cog = cog self . wheel = wheel def _ratio ( self ): return self . chainring / self . cog def gear_inches ( self ): return self . _ratio () * self . wheel . diameter () # call private method class TestGear : def test_calculates_ratio ( self ): ## \u2b05 test private method wheel = Wheel ( 26 , 1.5 ) gear = Gear ( 52 , 11 , wheel ) assert gear . _ratio == pytest . approx ( 4.7 , 0.01 ) ## call to self ## \u2b06 this is redundant test. `gear_inches` return value is proof enough ## don\u2019t test private method (assert / expectation). Don\u2019t!","title":"Sent to self (Ignore)"},{"location":"guide/test-minimalist/#outgoing","text":"","title":"Outgoing"},{"location":"guide/test-minimalist/#outgoing-query-ignore","text":"class Wheel : def __init__ ( self , rim , tire ): self . rim = rim self . tire = tire def diameter ( self ): return self . rim + ( self . tire * 2 ) class Gear : def __init__ ( self , chainring , cog , wheel ): self . chainring = chainring self . cog = cog self . wheel = wheel def _ratio ( self ): return self . chainring / self . cog def gear_inches ( self ): return self . _ratio () * self . wheel . diameter () # call other class (outgoing) class TestGear : def test_calculates_gear_inches ( self ): wheel = Wheel ( 26 , 1.5 ) gear = Gear ( 52 , 11 , wheel ) # test outgoing command `wheel.diameter()` assert gear . wheel . diameter () == 29 ## \u2b06 this is already done in `Wheel` test (redundant)","title":"Outgoing Query (Ignore)"},{"location":"guide/test-minimalist/#outgoing-command-expect-to-send","text":"# assert someting (side effect) in far away. # This is not `Gear` responsibility. # This is an integration test, not unit test.","title":"Outgoing Command (Expect to send)"},{"location":"guide/test-minimalist/#credits","text":"https://www.youtube.com/watch?v=URSWYvyc42M https://speakerdeck.com/skmetz/magic-tricks-of-testing-railsconf","title":"Credits"}]}